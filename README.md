ğŸ“© Spam Detector (LSTM) Author: Praveen Arella A simple LSTM-based spam classifier with a FastAPI web interface (HTML UI + JSON API). This project demonstrates the full ML pipeline â€” preprocessing â†’ tokenization â†’ LSTM model training â†’ model export â†’ production inference through FastAPI.

ğŸ“ Project Structure project/ â”‚â”€â”€ app.py # FastAPI app (UI + JSON API) â”‚â”€â”€ lstm_training.py # Model training script â”‚â”€â”€ tokenizer.pkl # Saved tokenizer â”‚â”€â”€ spam_lstm_model_tf/ # Saved model directory (or spam_lstm_model.h5) â”‚â”€â”€ templates/ â”‚ â””â”€â”€ index.html # Web UI â”‚â”€â”€ static/ # CSS / JS â”‚â”€â”€ requirements.txt # Dependencies â”‚â”€â”€ README.md # Documentation

ğŸ” Key Notes

clean_text() â†’ stopwords + stemming.

encode() â†’ loads tokenizer.pkl and applies pad_sequences(MAX_LEN).

API Endpoints:

GET / â†’ Web UI

POST /predict â†’ JSON API

POST /predict_form â†’ HTML form submission

ğŸ“Š Model Metrics Training: 6 epochs âœ” Training Summary

Final Training Accuracy: 0.9966

Final Validation Accuracy: ~0.9749

âœ” Test Set Evaluation

Accuracy: 0.9766

âœ” Classification Report ClassPrecisionRecallF1-scoreSupportHAM (0)0.970.980.98149SPAM (1)0.980.970.98150 â¡ Macro F1-score ~0.98 âœ” Interpretation

High precision â†’ very few ham misclassified as spam

High recall â†’ spam is rarely missed

Balanced F1 â†’ overall strong model performance

âœ” Recommended Validations

Ensure no data leakage

Use stratified train-test split

Consider k-fold cross-validation

Test with real-world messages

â–¶ How to Run (Windows / PowerShell) 1ï¸âƒ£ Create Virtual Environment python -m venv .venv ..venv\Scripts\Activate python -m pip install --upgrade pip

2ï¸âƒ£ Install Dependencies pip install -r requirements.txt

3ï¸âƒ£ Download NLTK Stopwords python -m nltk.downloader stopwords

4ï¸âƒ£ Train the Model python lstm_training.py

This will generate:

tokenizer.pkl

spam_lstm_model_tf/ or spam_lstm_model.h5

5ï¸âƒ£ Start FastAPI Server uvicorn app:app --reload --host 0.0.0.0 --port 8000

Web UI: http://127.0.0.1:8000

JSON API: POST â†’ http://127.0.0.1:8000/predict

ğŸ§ª Example API Request (cURL) curl -X POST "http://127.0.0.1:8000/predict" ^ -H "Content-Type: application/json" ^ -d "{"message": "Congratulations! You've won a prize"}"

âš  Troubleshooting â— 1. ValueError: Unrecognized keyword arguments passed to LSTM: {'time_major': False} Cause: Mismatch between TensorFlow version during training vs inference. Quick Fix (in app.py): Wrap model loading with compatibility layers. Long-Term Fix: Re-train and save using the new format: model.save("spam_lstm_model.keras")

Also: pin TensorFlow version in requirements.txt.

â— 2. NLTK Stopwords Error Run: python -m nltk.downloader stopwords

ğŸ”’ Production Considerations ğŸ“¦ Environment

Pin versions in requirements.txt

Optional: build Dockerfile

ğŸ“¦ Model Lifecycle

Version models (model_v1, model_v2â€¦)

Add metadata endpoint

ğŸ” Testing

Unit tests for preprocessing + tokenization

Integration test with full inference

ğŸ” Security

Validate input JSON

Restrict CORS

Sanitize user messages

ğŸš€ Future Improvements

Add real-world dataset for robustness

Perform k-fold validation

Try Transformer-based models

Add ROC-AUC, PR curves

Add confusion matrix visualization

ğŸ“œ License Choose and include a license (MIT recommended).
